19 Jan 2016: JD, CS, ML

We will try to build a multi-level, multivariate-response model:

women's FGC status; FGC belief 
	--> overall FGC future; daughter's future FGC status

We are starting with four data sets (ke5, ng5, ml5, sl5).

Our next step is to look at PCA analyses of responses about FGC benefit.

We might look into logistic PCA

----------------------------------------------------------------------

08 Mar 2016: ML

We will build the univariate response model first with using clmm2 clusterid as random effect 

Done. now try to do the bolker MANOVA trick. (Is that what we are going to call it from now on?)

I set it up correctly (I think) with random effect (1|clusterId) + (1|clusterId:id) but it is complaining about 
optimizer nlminb failed to converge

Baseline is causing a problem. We can't get rid of the intercept(baseline/contrasting level) it cases a problem in id/obs RE


----------------------------------------------------------------------

09 Mar 2016 

ML: made an attempt of the bolker MANOVA trick and JD will take a shot at it
multi_fit.R

----------------------------------------------------------------------

11 Mar 2016

ML took Bolker's advice and lumped maybes and yes together and fit a binomial glmer.
Still no success but good attempt. Maybe need to look up multivariate complete separation.

----------------------------------------------------------------------

14 Mar 2016

multi_fit seem to work, still need to clarify the RE. Going to try logistic PCA next

----------------------------------------------------------------------

15 Mar 2016

Did not try logistic PCA, trying to get a sense of what is going on with RE

Try logistic PCA and don't know what is going on.

Had a meeting with JD and CF, did a lot of code clean up.

Made a mcmcglmm model, but I don't know how to read it

----------------------------------------------------------------------

17 March 2016

Can't improve the mixing for mcmcglmm. Going to do some simulation with bolker and testing bolker manova trick

----------------------------------------------------------------------

18 March 2016

Ian suggested trying to fit the model in stan

----------------------------------------------------------------------

03/30/16:  
Mike did the statistics of the four countries separately, usig ? model?  
We now lean towards doing a big model (using MCMC?) by merging all the data. The big modle givs us more statistical power, 
but also allows us to compare the differences among the countries.  Some questions remains before proceeding to a big model:

----------------------------------------------------------------------

04/04/16:
ML will recompute the benefit score and check correlation with PC score for all countries. Big model should not be that hard, but we should include another layer of benefit score. ie. individual level/ community level/ country level. This also suggest we should use the averaging (with proper standardization) instead of PC. In theory, this is what "CPC" common principal components are for, but let's not go there.

Everything above is done, now I am going to "merge" the data together (ie combine all the country data together)

----------------------------------------------------------------------

Tue Apr  5 2016

Decided to take a hypothesis-testing approach: more is therefore more.

Decided to stick with splines, because we are stubborn and think they're really a bit better as a way to deal with quantitative variables

Religion and ethnicity are now fixed variables, and we are going to de-nest ethnicity from country.

Mike needs to follow the pipeline and find out why we still have NAs.

C. needs to make a final decision about which community-level factors to include:

IN:

* benefit, fgc, att

Consider

* media, wealth, edu

Arising: do we want to score education, or keep it categorical?


----------------------------------------------------------------------

06/04/16
Mike fixed the whole pipeline. NA's are caused by incomplete cases and if bene/att/media has a row of ALL NAs. Everything is fixed and can run/fit in MCMCglmm.

Mike's thoughts: It is good we have a big multivariate model, but at the same time, we are throwing away a lot of data. (ie, some countries do not have a lot of data on futurefgcDau). A rough estimate of 60% data are thrown out.

 ----------------------------------------------------------------------
08/04/16
We found a problem of missing all the women who answered no daughter to be cut in our main model.  So we need to reset our models:
+ The first (or the main) model will be using fgc beneifts and women's fgc status as the main predictors and with two responses:  "whether to cut their daughter" and "whether to continue fgc."  I believe that we already did this one by using mcmc.
+ The secondary model will be using the same predictors (fgc beneifts and women's fgc status) with only one response: "whether to continue fgc".  In this model, all the women (despite with or without daughters to be cut) will be included in the analysis.
+ Regarding the main model (mcmc model), we also need to think about the interaction between fgc benefits and gender attitudes, because we believe that these two variables has a potential "strong" correlation with each other and need to be tested.  Mike said it can be done by coding "bene x att."
+ another confusing but minor questions:  why don't we just put all the predictors in a x b x c x .....?

11/04/16
ML will remodel the univariate models again via clmm and mcmcglmm.
ML finish making univariate MCMCglmm model, going to refit in clmm
ML I think the problem right now is we added too many covariates into the model. This can lead to (most likely why it is not working for me) is that we are thinning the sample sizes too small such that we have samples with the same response. In theory, and assuming we don't have complete separation problem, we need at last 1 person for each response level. ... complete separation is the next step after this. I tried running all.futurefgcDau.clmm.Rout and not done after 2 hours. 

12/04/16

ML will test complete separation problem with just ethni as covariate. It seems to be a problem in both fixed and random effect, not enough time to investigate, check out error_test.R

----------------
May23 2018: (after years!)

There are 3 models:
 
Main model: fgc daughter future ~ others (women's attitudes in fgc beliefs and their fgc status predicting daughter's fgc future)
Structuarl model 1: fgc Future ~ others (women's attitudes in fgc beliefs predicting fgc future)
1a:  all women
1b: women with daughters to be fgc only
Structuarl model 2: fgc daughter future ~ others (women's attitudes in fgc beliefs, their fgc status and their attitudes of fgc continuity predicting daughter's fgc future)

How about daughters' age?
To find out why did we decide not to use women's daughters who were fgced already.  So far, we can't decide what's the best.
